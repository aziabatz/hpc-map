# @package _global_

defaults:
  - override /model: deepaco.yaml
  - override /env: mpimap.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /logger: wandb.yaml

env:
  num_procs: 128
  num_machines: 32
  max_machine_capacity: 4
  normalize: True

logger:
  wandb:
    project: "mpi_mapping"
    tags: ["deepaco", "${env.name}"]
    group: ${env.name}_procs_${env.num_procs}
    name: deepaco-${env.name}-${env.num_procs}_${env.num_machines}_${model.batch_size}_${model.train_data_size}_${trainer.max_epochs}

model:
  batch_size: 4
  val_batch_size: 4
  test_batch_size: 4
  train_data_size: 50
  val_data_size: 20
  test_data_size: 100
  optimizer_kwargs:
    lr: 1e-4
    weight_decay: 0.1
  lr_scheduler:
    "MultiStepLR"
  lr_scheduler_kwargs:
    milestones: [80, 95]
    gamma: 0.1

  policy_kwargs:
    n_ants:
      train: ${model.batch_size}
      val: ${model.batch_size}
      test: ${model.batch_size}
    n_iterations:
      train: 1 # unused value
      val: 30
      test: 100
    alpha: 1.0
    beta: 1.0
    decay: 0.95


trainer:
  max_epochs: 100
  log_every_n_steps: ${model.batch_size}


seed: 1234