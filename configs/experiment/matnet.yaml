# @package _global_

defaults:
  - override /model: matnet.yaml
  - override /env: mpimap.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /logger: wandb.yaml

env:
  num_procs: 12
  num_machines: 3
  max_machine_capacity: 4
  normalize: False

  data_dir: ${paths.root_dir}/data/mpi
  #val_file: all_${env.num_procs}.npz
  test_file: all_${env.num_procs}.npz

logger:
  wandb:
    project: "mpi_mapping"
    tags: ["matnet", "${env.name}"]
    group: ${env.name}_procs_${env.num_procs}
    name: matnet-${env.name}-${env.num_procs}_${env.num_machines}_${model.batch_size}_${model.train_data_size}_${trainer.max_epochs}

model:
#  mode: "Random"
  batch_size: 2
  val_batch_size: 2
  test_batch_size: 2
  train_data_size: 32
  val_data_size: 16
  test_data_size: 16
  optimizer:
    "RAdam"
  optimizer_kwargs:
    lr: 1.5e-4
    weight_decay: 0
  lr_scheduler:
    "MultiStepLR"
    #"ReduceLROnPlateau"
  lr_scheduler_kwargs:
    milestones: [80, 95]
    # mode: 'min'
    # factor: 0.7
    # patience: 100
    # verbose: True
  feats: "cost_matrix"

trainer:
  max_epochs: 1
  log_every_n_steps: ${model.batch_size}

seed: 1234